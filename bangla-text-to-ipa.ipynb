{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\ntrain_df = pd.read_csv(\"/kaggle/input/dataverse_2023/trainIPAdb_u.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/dataverse_2023/testData.csv\", index_col=\"row_id_column_name\")\n\nprint(\"Total number of training samples:\", len(train_df))\nprint(\"Total number of test samples:\", len(test_df))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seaborn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n\ntrain_lengths = train_df[\"text\"].str.len()\nsns.histplot(ax=axes[0], data=train_lengths, bins=10).set(xlabel=\"Length of training text samples\")\naxes[0].axvline(train_lengths.mean(), c=\"k\", ls=\"--\", lw=2.5, label=\"Mean\")\naxes[0].legend()\n\ntest_lengths = test_df[\"text\"].str.len()\nsns.histplot(ax=axes[1], data=test_lengths, bins=10).set(xlabel=\"Length of test text samples\")\naxes[1].axvline(test_lengths.mean(), c=\"k\", ls=\"--\", lw=2.5, label=\"Mean\")\naxes[1].legend()\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ntrain_corpus = train_df[\"text\"].sum()\ntest_corpus = test_df[\"text\"].sum()\n\n# Remove punctuations\nchars_to_ignore = '[-,\\.:;\\'\"!\\?।]'\n\ntrain_corpus = re.sub(chars_to_ignore, ' ', train_corpus)\ntrain_vocab = set(train_corpus.split())\n\ntest_corpus = re.sub(chars_to_ignore, ' ', test_corpus)\ntest_vocab = set(test_corpus.split())\n\noov = test_vocab - train_vocab\n\nprint(\"Number of unique words in training data:\", len(train_vocab))\nprint(\"Number of unique words in test data:\", len(test_vocab))\nprint(\"Number of out-of-vocabulary (OOV) words:\", len(oov))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtering text samples that contain English alphanumeric values\nfiltered_train = train_df[lambda x: x[\"text\"].str.contains(\"[A-Za-z0-9]\")]\n\nwith pd.option_context('display.max_colwidth', 0):\n    display(filtered_train.tail(n=10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bangla_numerals = \"[০১২৩৪৫৬৭৮৯]\"\n\nfiltered_train = train_df[lambda x: x[\"text\"].str.contains(bangla_numerals)]\nfiltered_test = test_df[lambda x: x[\"text\"].str.contains(bangla_numerals)]\n\nprint(\"Number of training samples containing Bangla numerals:\", len(filtered_train))\nprint(\"Number of test samples containing Bangla numerals:\", len(filtered_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install jiwer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha_pat = \"[a-zA-z0-9]\"\n\ntrain_df[\"text\"] = train_df[\"text\"].str.replace(alpha_pat, \"\", regex=True)\ntest_df[\"text\"] = test_df[\"text\"].str.replace(alpha_pat, \"\", regex=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, shuffle=True, random_state=3000)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\nds_train = Dataset.from_pandas(train_df)\nds_eval = Dataset.from_pandas(val_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n\nmodel_id = \"csebuetnlp/banglat5\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id)\ndata_collator = DataCollatorForSeq2Seq(tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(sample):\n    output = tokenizer(sample[\"text\"])\n    output[\"labels\"] = tokenizer(sample[\"ipa\"])['input_ids']\n    output[\"length\"] = len(output[\"labels\"])\n    return output\n\n\nds_train = ds_train.map(prepare_dataset, remove_columns=ds_train.column_names)\nds_eval = ds_eval.map(prepare_dataset, remove_columns=ds_eval.column_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom datasets import load_metric\n\nwer_metric = load_metric(\"wer\")\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    \n    if isinstance(preds, tuple):\n        preds = preds[0]\n    \n    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = wer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"wer\": result}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\nmodel_id = \"mt5-bangla-text-to-ipa\"\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=model_id,\n    group_by_length=True,\n    length_column_name=\"length\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=16,\n    evaluation_strategy=\"steps\",\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    load_best_model_at_end=True,\n    num_train_epochs=10,\n    save_steps=4000,\n    eval_steps=4000,\n    logging_steps=4000,\n    learning_rate=3e-4,\n    weight_decay=1e-2,\n    warmup_steps=2000,\n    save_total_limit=2,\n    predict_with_generate=True,\n    generation_max_length=128,\n    push_to_hub=False,\n    report_to=\"none\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_args,\n    train_dataset=ds_train,\n    eval_dataset=ds_eval,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(model_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sort by length\nindex = test_df[\"text\"].str.len().sort_values(ascending=False).index\ntest_df = test_df.reindex(index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"text2text-generation\", model=model_id, device=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntexts = test_df[\"text\"].tolist()\nipas = pipe(texts, max_length=128, batch_size=16)\nipas = [ipa[\"generated_text\"] for ipa in ipas]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"ipa\"] = ipas\ntest_df = test_df.sort_index()\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv(\"submission.csv\", columns=[\"ipa\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}